{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d8bb34-6d97-41fc-bbe5-be2e322fe273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ef7d1a-8551-4a69-bcfe-71b606cc6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from torch.utils.data import DataLoader\n",
    "from modules.constants import feature_list\n",
    "from modules.data import GapFillingDataset\n",
    "from modules.mlp import MLP\n",
    "from modules.baseline import Baseline\n",
    "from modules.gapt import GapT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a13388c-2a28-41b9-b330-73099132846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 'two_week' # 'four_week'\n",
    "\n",
    "os.makedirs(f'results/{seq_len}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a551d3-7dd1-4a90-bb2d-6c35810b20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'results/mlp_{seq_len}_seq'\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(output_dir, 'metadata.json'), 'r') as f:\n",
    "    mlp_metadata = json.load(f)\n",
    "\n",
    "# Extract arguments from metadata\n",
    "args = mlp_metadata['args']\n",
    "\n",
    "# Initialize model from checkpoint\n",
    "mlp = MLP.load_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(args['output_dir'], 'model.ckpt'),\n",
    "    d_input=len(feature_list), \n",
    "    d_output=args['d_output'],\n",
    "    learning_rate=args['learning_rate'],\n",
    "    dropout_rate=args['dropout_rate'],\n",
    "    optimizer=args['optimizer'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17a67c5-92b9-4367-8824-b9466c99e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'results/baseline_{seq_len}_seq'\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(output_dir, 'metadata.json'), 'r') as f:\n",
    "    baseline_metadata = json.load(f)\n",
    "\n",
    "# Extract arguments from metadata\n",
    "args = baseline_metadata['args']\n",
    "\n",
    "# Initialize model from checkpoint\n",
    "baseline = Baseline.load_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(args['output_dir'], 'model.ckpt'),\n",
    "    d_input=len(feature_list), \n",
    "    n_head=args['n_head'], \n",
    "    d_model=args['d_model'], \n",
    "    d_output=args['d_output'],\n",
    "    d_embedding=args['d_embedding'],\n",
    "    learning_rate=args['learning_rate'],\n",
    "    dropout_rate=args['dropout_rate'],\n",
    "    optimizer=args['optimizer'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b58ff1-feb0-43b2-b593-4e20a95649e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'results/gapt_naive_{seq_len}_seq'\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(output_dir, 'metadata.json'), 'r') as f:\n",
    "    gapt_naive_metadata = json.load(f)\n",
    "\n",
    "# Extract arguments from metadata\n",
    "args = gapt_naive_metadata['args']\n",
    "\n",
    "# Initialize model from checkpoint\n",
    "gapt_naive = GapT.load_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(args['output_dir'], 'model.ckpt'),\n",
    "    d_input=len(feature_list), \n",
    "    n_head=args['n_head'],\n",
    "    d_feedforward=args['d_feedforward'],\n",
    "    d_model=args['d_model'], \n",
    "    n_layers=args['n_layers'], \n",
    "    d_output=args['d_output'],\n",
    "    learning_rate=args['learning_rate'],\n",
    "    dropout_rate=args['dropout_rate'],\n",
    "    optimizer=args['optimizer'],\n",
    "    mode=args['mode'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3513b1-f7cf-44a5-8af8-16da8898751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'results/gapt_default_{seq_len}_seq'\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(output_dir, 'metadata.json'), 'r') as f:\n",
    "    gapt_metadata = json.load(f)\n",
    "\n",
    "# Extract arguments from metadata\n",
    "args = gapt_metadata['args']\n",
    "\n",
    "# Initialize model from checkpoint\n",
    "gapt = GapT.load_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(args['output_dir'], 'model.ckpt'),\n",
    "    d_input=len(feature_list), \n",
    "    n_head=args['n_head'],\n",
    "    d_feedforward=args['d_feedforward'],\n",
    "    d_model=args['d_model'], \n",
    "    n_layers=args['n_layers'], \n",
    "    d_output=args['d_output'],\n",
    "    learning_rate=args['learning_rate'],\n",
    "    dropout_rate=args['dropout_rate'],\n",
    "    optimizer=args['optimizer'],\n",
    "    mode=args['mode'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b41f2ab-4103-4aca-9a76-8974f1754340",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(args['data_dir'], 'paths.json'), 'r') as f:\n",
    "    data_paths = json.load(f)\n",
    "\n",
    "test_dataset = GapFillingDataset(data_paths['test'], gapt_metadata['feature_list'])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4355c12-fdb5-47db-a14a-09e1e632deb7",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35fe4200-e00c-486f-ba19-75705f7943f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0e2489b89a4a36bb81df3822a177b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set models to eval mode\n",
    "mlp.eval()\n",
    "baseline.eval()\n",
    "gapt_naive.eval()\n",
    "gapt.eval()\n",
    "\n",
    "# Initialize a dictionary to store metrics per key\n",
    "metrics_by_key = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Loop over batches\n",
    "for batch in tqdm(test_dataloader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mlp_predictions = mlp(batch)\n",
    "        baseline_predictions = baseline(batch)\n",
    "        gapt_naive_predictions = gapt_naive(batch)\n",
    "        gapt_predictions = gapt(batch)\n",
    "    \n",
    "    target = batch['target'].cpu().detach().numpy()\n",
    "    baseline_predictions = baseline_predictions.cpu().detach().numpy()\n",
    "    gapt_predictions = gapt_predictions.cpu().detach().numpy()\n",
    "    mlp_predictions = mlp_predictions.cpu().detach().numpy()\n",
    "    gapt_naive_predictions = gapt_naive_predictions.cpu().detach().numpy()\n",
    "    mask = batch['mask'].cpu().detach().numpy()\n",
    "    file = batch['file']\n",
    "    \n",
    "    inverted_mask = ~mask\n",
    "\n",
    "    for idx in range(target.shape[0]):\n",
    "        key = file[idx].split('/')[-1].split('.')[0].split('_')[0]\n",
    "        true_values = np.exp(target[idx][inverted_mask[idx]])\n",
    "        \n",
    "        baseline_pred = np.exp(baseline_predictions[idx][inverted_mask[idx]])\n",
    "        gapt_pred = np.exp(gapt_predictions[idx][inverted_mask[idx]])\n",
    "        mlp_pred = np.exp(mlp_predictions[idx][inverted_mask[idx]])\n",
    "        gapt_naive_pred = np.exp(gapt_naive_predictions[idx][inverted_mask[idx]])\n",
    "        \n",
    "        if 'target_values' not in metrics_by_key[key]:\n",
    "            metrics_by_key[key]['target_values'] = []\n",
    "        metrics_by_key[key]['target_values'].extend(list(true_values))\n",
    "\n",
    "        # Accumulate errors by key       \n",
    "        metrics_by_key[key]['baseline_rmse'].append(np.sqrt(mean_squared_error(true_values, baseline_pred)))\n",
    "        metrics_by_key[key]['gapt_naive_rmse'].append(np.sqrt(mean_squared_error(true_values, gapt_naive_pred)))\n",
    "        metrics_by_key[key]['gapt_rmse'].append(np.sqrt(mean_squared_error(true_values, gapt_pred)))\n",
    "        metrics_by_key[key]['mlp_rmse'].append(np.sqrt(mean_squared_error(true_values, mlp_pred)))\n",
    "        \n",
    "        metrics_by_key[key]['mlp_mae'].append(mean_absolute_error(true_values, mlp_pred))\n",
    "        metrics_by_key[key]['baseline_mae'].append(mean_absolute_error(true_values, baseline_pred))\n",
    "        metrics_by_key[key]['gapt_naive_mae'].append(mean_absolute_error(true_values, gapt_naive_pred))\n",
    "        metrics_by_key[key]['gapt_mae'].append(mean_absolute_error(true_values, gapt_pred))\n",
    "\n",
    "        metrics_by_key[key]['mlp_mbe'].append(np.mean(mlp_pred - true_values))\n",
    "        metrics_by_key[key]['baseline_mbe'].append(np.mean(baseline_pred - true_values))\n",
    "        metrics_by_key[key]['gapt_naive_mbe'].append(np.mean(gapt_naive_pred - true_values))\n",
    "        metrics_by_key[key]['gapt_mbe'].append(np.mean(gapt_pred - true_values))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54537e0-2b74-41a7-bdac-2fa5f13c0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{seq_len}/station_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(metrics_by_key), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1151b44-7638-4511-b645-15796d6745c0",
   "metadata": {},
   "source": [
    "**How to read the data from file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d17a468c-5e30-466c-869c-312a853366bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{seq_len}/station_metrics.pkl', 'rb') as f:\n",
    "    metrics_by_key = pickle.load(f)\n",
    "\n",
    "metrics_by_key = defaultdict(lambda: defaultdict(list), metrics_by_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbaa9b85-9f7a-4f53-8b70-fa4178c6f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fb1167e05f4bcfbdb66561c32e4e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_by_key = {}\n",
    "for key, metrics in tqdm(metrics_by_key.items()):\n",
    "    results_by_key[key] = {}\n",
    "    \n",
    "    # Calculate average target value for each key\n",
    "    avg_target_value = np.mean(metrics['target_values'])\n",
    "    results_by_key[key]['average_target'] = float(avg_target_value)\n",
    "    \n",
    "    for metric_name, values in metrics.items():\n",
    "        if metric_name != 'target_values':\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values)\n",
    "            results_by_key[key][metric_name + '_mean'] = float(mean_val)\n",
    "            results_by_key[key][metric_name + '_std'] = float(std_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6f0db3-98c5-4dfd-8ec7-cb6ec556ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{seq_len}/station_metrics.json', 'w') as f:\n",
    "    json.dump(results_by_key, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4f1db20-6485-44c1-96b1-107532581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store metrics for each model\n",
    "metrics = {\n",
    "    'mlp': {'rmse': [], 'mae': [], 'mbe': [], 'nrmse': [], 'nmae': [], 'nmbe': []},\n",
    "    'baseline': {'rmse': [], 'mae': [], 'mbe': [], 'nrmse': [], 'nmae': [], 'nmbe': []},\n",
    "    'gapt_naive': {'rmse': [], 'mae': [], 'mbe': [], 'nrmse': [], 'nmae': [], 'nmbe': []},\n",
    "    'gapt': {'rmse': [], 'mae': [], 'mbe': [], 'nrmse': [], 'nmae': [], 'nmbe': []}\n",
    "}\n",
    "\n",
    "# Extract metrics for each model across all stations and calculate normalized metrics\n",
    "for key, value in metrics_by_key.items():\n",
    "    target_mean = np.mean(value['target_values'])\n",
    "    \n",
    "    for model_name in metrics:\n",
    "        metrics[model_name]['rmse'].extend(value[f'{model_name}_rmse'])\n",
    "        metrics[model_name]['mae'].extend(value[f'{model_name}_mae'])\n",
    "        metrics[model_name]['mbe'].extend(value[f'{model_name}_mbe'])\n",
    "\n",
    "        # Normalized metrics\n",
    "        metrics[model_name]['nrmse'].extend([x/target_mean for x in value[f'{model_name}_rmse']])\n",
    "        metrics[model_name]['nmae'].extend([x/target_mean for x in value[f'{model_name}_mae']])\n",
    "        metrics[model_name]['nmbe'].extend([x/target_mean for x in value[f'{model_name}_mbe']])\n",
    "\n",
    "# Compute mean and standard deviation for each metric of each model\n",
    "results = {}\n",
    "for model_name, model_metrics in metrics.items():\n",
    "    results[model_name] = {}\n",
    "    for metric_name, metric_values in model_metrics.items():\n",
    "        mean_value = np.mean(metric_values)\n",
    "        std_value = np.std(metric_values)\n",
    "        results[model_name][f'{metric_name}_mean'] = float(mean_value)\n",
    "        results[model_name][f'{metric_name}_std'] = float(std_value)\n",
    "\n",
    "with open(f'results/{seq_len}/metrics.json', 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49114a12-33c7-49d7-a480-66ae21ce55ee",
   "metadata": {},
   "source": [
    "### Plot comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd773bcc-1fe5-40bf-b518-30164568b4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc60fcd72b1f4c4d92f5e6a2fd18b013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eabb387fd694dcb8dd214027d726232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a09dbd3a584681807a23e76a6e0c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfe6b8178614914ab20b693daeaa62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c107ee2646cb4bdb9429c5ee4f716359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.eval()\n",
    "baseline.eval()\n",
    "gapt_naive.eval()\n",
    "gapt.eval()\n",
    "\n",
    "n = 0\n",
    "num_batches = 5\n",
    "\n",
    "for ext in ['png', 'pdf']:\n",
    "    os.makedirs(f'figures/{seq_len}/{ext}', exist_ok=True)\n",
    "\n",
    "with open('data/measurement_sites.json', 'r') as file:\n",
    "    measurement_sites = pd.read_json(file)\n",
    "    \n",
    "for batch in test_dataloader:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mlp_predictions = np.exp(mlp(batch)).numpy()\n",
    "        baseline_predictions = np.exp(baseline(batch)).numpy()\n",
    "        gapt_naive_predictions = np.exp(gapt_naive(batch)).numpy()\n",
    "        gapt_predictions = np.exp(gapt(batch)).numpy()\n",
    "    \n",
    "    date = batch['unix_date'].numpy()\n",
    "    mask = batch['mask'].numpy()\n",
    "    target = np.exp(batch['target'].numpy())\n",
    "    file = batch['file']\n",
    "    \n",
    "    inverted_mask = ~mask\n",
    "\n",
    "    for idx in tqdm(range(gapt_metadata['args']['batch_size'])):\n",
    "        mlp_rmse = np.sqrt(mean_squared_error(target[idx][inverted_mask[idx]], mlp_predictions[idx][inverted_mask[idx]]))\n",
    "        baseline_rmse = np.sqrt(mean_squared_error(target[idx][inverted_mask[idx]], baseline_predictions[idx][inverted_mask[idx]]))\n",
    "        gapt_naive_rmse = np.sqrt(mean_squared_error(target[idx][inverted_mask[idx]], gapt_naive_predictions[idx][inverted_mask[idx]]))\n",
    "        gapt_rmse = np.sqrt(mean_squared_error(target[idx][inverted_mask[idx]], gapt_predictions[idx][inverted_mask[idx]]))\n",
    "    \n",
    "        sample_date = pd.to_datetime(date[idx], unit='s')\n",
    "        \n",
    "        gap_indices = np.where(mask[idx] == False)\n",
    "        \n",
    "        key = file[idx].split('/')[-1].split('.')[0].split('_')[0]\n",
    "        station_name = measurement_sites[key]['station_name']\n",
    "        environment_type = ' '.join(measurement_sites[key]['environment_type'].split('_'))\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(sample_date, mlp_predictions[idx], label=f'MLP (RMSE={mlp_rmse:.2f})', c='tab:blue')\n",
    "        plt.plot(sample_date, baseline_predictions[idx], label=f'Richard et al. (RMSE={baseline_rmse:.2f})', c='tab:orange')\n",
    "        plt.plot(sample_date, gapt_naive_predictions[idx], label=f'GapT naive (RMSE={gapt_naive_rmse:.2f})', c='tab:green')\n",
    "        plt.plot(sample_date, gapt_predictions[idx], label=f'GapT (RMSE={gapt_rmse:.2f})', c='tab:purple')\n",
    "        plt.plot(sample_date, target[idx], label='Ground truth', c='tab:red')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(r'N100 Concentration (cm$^{-3}$)')\n",
    "        plt.title(f'{station_name} ({environment_type})')\n",
    "        plt.legend(frameon=False)\n",
    "        \n",
    "        segment = file[idx].split('/')[-1].split('.')[0]\n",
    "        for ext in ['png', 'pdf']:\n",
    "            pdf_save_path = f'figures/{seq_len}/{ext}/{segment}_{n}_{idx}.{ext}'\n",
    "            plt.savefig(pdf_save_path)\n",
    "\n",
    "        plt.close()\n",
    "        \n",
    "    n += 1\n",
    "    if n == num_batches:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf1652-7d09-46ce-9128-be900332eb44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
