{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ellarauth/CCN-proxy-modeling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the measurement station codes (35 stations)\n",
    "# more detailed information on the stations can be found in metadata/measurement_sites_info.txt\n",
    "stations = ['ABZ', 'ALE', 'AMA', 'AMM', 'ASP', 'BEI', 'BOT', 'BSL', 'DEL', 'EGB',\n",
    "            'FKL', 'HAD', 'HEL', 'HPB', 'HRW', 'HYY', 'KCE', 'KPZ', 'MAR', 'MHD', \n",
    "            'MLP', 'MUK', 'NAN', 'NEU', 'POV', 'SAO', 'SCH', 'SGP', 'UAE', 'PRL',\n",
    "            'VAR', 'VHL', 'VIE', 'WAL', 'ZOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets(folder):\n",
    "    '''\n",
    "    Concatenates the individual datasets for all measurement stations in a specified folder located in \"data/\".\n",
    "    \n",
    "    Parameters:\n",
    "    folder (str): Name of folder located in the \"data/\" folder of the repository\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: data frame of the concatenated data sets in the folder\n",
    "    '''\n",
    "    \n",
    "    full_df = []\n",
    "\n",
    "    for s in stations:\n",
    "        df = pd.read_csv('data/'+folder+'/'+s+'.csv')\n",
    "        df['station'] = s\n",
    "        full_df.append(df)\n",
    "\n",
    "    full_df = pd.concat(full_df)\n",
    "    full_df = full_df.reset_index(drop=True)\n",
    "    full_df['id'] = [full_df.station[i] + '-' + str(full_df.date[i]) for i in range(full_df.shape[0])]\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the aerosol mixing ratio data and saving it as a separate csv file\n",
    "# a full description of all variable names can be found in metadata/variable_names.txt\n",
    "aerosols_df = combine_datasets('aerosols')\n",
    "aerosols_df = aerosols_df[['id', 'latitude', 'longitude', 'aermr01', 'aermr02', \n",
    "                           'aermr03', 'aermr04', 'aermr05', 'aermr06', 'aermr07', \n",
    "                           'aermr08', 'aermr09', 'aermr10', 'aermr11']]\n",
    "aerosols_df.to_csv('data/aerosols_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the atmospheric data, calculating the relative humidity, and saving it as a separate csv file\n",
    "atmospheric_df = combine_datasets('atmospheric')\n",
    "atmospheric_df = atmospheric_df[['id', 'd2m', 't2m']]\n",
    "td = atmospheric_df.d2m - 273.15\n",
    "t = atmospheric_df.t2m - 273.15\n",
    "atmospheric_df['rh'] = 100*(np.exp((17.625*td) / (243.04+td)) / np.exp((17.625*t) / (243.04+t)))\n",
    "atmospheric_df.to_csv('data/atmospheric_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the boundary layer height data and saving it as a separate csv file\n",
    "boundary_layer_height_df = combine_datasets('boundary_layer_height')\n",
    "boundary_layer_height_df = boundary_layer_height_df[['id', 'blh']]\n",
    "boundary_layer_height_df.to_csv('data/boundary_layer_height_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the gas data and saving it as a separate csv file\n",
    "gases_df = combine_datasets('gases')\n",
    "gases_df = gases_df[['id', 'co', 'c5h8', 'no2', 'no', 'so2']]\n",
    "gases_df.to_csv('data/gases_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the slow access data and saving it as a separate csv file\n",
    "slow_access_df = combine_datasets('slow_access')\n",
    "slow_access_df = slow_access_df[['id', 'nh3', 'crwc', 'c10h16']]\n",
    "slow_access_df.to_csv('data/slow_access_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the wind data, calculating the wind speed, and saving it as a separate csv file\n",
    "wind_df = combine_datasets('wind')\n",
    "wind_df['wind_speed'] = np.sqrt(wind_df.u**2 + wind_df.v**2)\n",
    "wind_df = wind_df[['id', 'wind_speed']]\n",
    "wind_df.to_csv('data/wind.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg(df, idx):\n",
    "    window = pd.Timedelta('1.5 hours')\n",
    "    start_time = idx - window\n",
    "    end_time = idx + window\n",
    "    mask = (df.index >= start_time) & (df.index <= end_time)\n",
    "    return df.loc[mask].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the n100 data and saving it as a separate csv file\n",
    "n100_df = []\n",
    "for s in stations:\n",
    "    df = pd.read_table(f'data/N100_proxy/{s}_N100.dat', sep='\\s+', \n",
    "                       names=['year', 'month', 'day', 'hour', 'minute', 'n100'])\n",
    "    \n",
    "    # AMA and UAE are in UTC, so the times of the measurements need to be adjusted to local time\n",
    "    if (s == 'AMA'):\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.date -= timedelta(hours=4)     \n",
    "    elif (s == 'UAE'):\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.date += timedelta(hours=4)\n",
    "        \n",
    "    # the year for FKL is multiplied by 2 due to some bug, so needs to be corrected\n",
    "    elif (s == 'FKL'):\n",
    "        df.year /= 2\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])  \n",
    "        \n",
    "    else:\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "    \n",
    "    df.drop(columns=['year', 'month', 'day', 'hour', 'minute'], inplace=True)\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # create empty 3 hourly dataframe - normalize converts time to midnight\n",
    "    every_3h_index = pd.date_range(df.index.min().normalize(), df.index.max(), freq='3H')\n",
    "    every_3h_df = pd.DataFrame(index=every_3h_index, columns=['n100'])\n",
    "    \n",
    "    # concatenate original and 3 hourly df, drop duplicate timestamps keeping observed values\n",
    "    df = pd.concat([df, every_3h_df], join='outer').sort_index()\n",
    "    \n",
    "    # loop over all rows and replace all 3 hourly NaNs with the average of all values within +/- 1.5 hour\n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isna(row['n100']):\n",
    "            avg = get_avg(df, idx)\n",
    "            df.loc[idx, 'n100'] = avg.n100\n",
    "    \n",
    "    # locate duplicate timestamps and keep the averaged value\n",
    "    df = df.loc[~df.index.duplicated(keep='last')]\n",
    "    \n",
    "    # drop edge cases\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df['date'] = df.index\n",
    "    df['station'] = s\n",
    "    n100_df.append(df)\n",
    "\n",
    "n100_df = pd.concat(n100_df)\n",
    "n100_df = n100_df[n100_df.n100 > 0]\n",
    "n100_df = n100_df.reset_index(drop=True)\n",
    "n100_df['id'] = [n100_df.station[i] + '-' + str(n100_df.date[i]) for i in range(n100_df.shape[0])]\n",
    "n100_df = n100_df[['id', 'station', 'date', 'n100']]\n",
    "n100_df.to_csv('data/n100_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n100_df = pd.read_csv('data/n100_data.csv')\n",
    "n100_df = n100_df.sort_values(['station', 'date'])\n",
    "n100_df['date'] = pd.to_datetime(n100_df['date'])\n",
    "n100_df.set_index('date', inplace=True)\n",
    "n100_df['date'] = n100_df.index\n",
    "\n",
    "def resample_group(group):\n",
    "    group = group.resample('3H').asfreq()\n",
    "    group['station'].ffill(inplace=True)  # forward fill for station\n",
    "    group['date'] = group.index      # Fill date_copy with index values\n",
    "    return group\n",
    "\n",
    "n100_df = n100_df.groupby('station').apply(resample_group)\n",
    "n100_df.dropna(subset=['station'], inplace=True)\n",
    "n100_df.reset_index(drop=True, inplace=True)\n",
    "n100_df['id'] = [n100_df.station[i] + '-' + str(n100_df.date[i]) for i in range(n100_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n100_df[n100_df['n100'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all the data sets into one dataframe\n",
    "data = n100_df.merge(aerosols_df, on='id')\n",
    "data = data.merge(atmospheric_df, on='id')\n",
    "data = data.merge(boundary_layer_height_df, on='id')\n",
    "data = data.merge(gases_df, on='id')\n",
    "data = data.merge(slow_access_df, on='id')\n",
    "data = data.merge(wind_df, on='id')\n",
    "\n",
    "# removing outliers for VHL\n",
    "for i, row in data.loc[data.station == 'VHL'].iterrows():\n",
    "    if row.n100 > 10000:\n",
    "        data.drop(index=i, inplace=True)\n",
    "\n",
    "# reordering the columns\n",
    "data = data[['id', 'station', 'date', 'latitude', 'longitude', 'n100', \n",
    "             'aermr01', 'aermr02', 'aermr03', 'aermr04', 'aermr05', 'aermr06', 'aermr07', \n",
    "             'aermr08', 'aermr09', 'aermr10', 'aermr11', 'co', 'c5h8', 'c10h16', 'nh3', \n",
    "             'no', 'no2', 'so2', 'd2m', 't2m', 'crwc', 'blh', 'rh', 'wind_speed']]\n",
    "\n",
    "# saving the full dataset\n",
    "data.date = pd.to_datetime(data.date)\n",
    "columns_except_n100 = [col for col in data.columns if col != 'n100']\n",
    "data.dropna(subset=columns_except_n100, inplace=True)\n",
    "data.to_csv('data/gap_filling.csv', index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['n100'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/gap_filling.csv')\n",
    "\n",
    "with open('data/measurement_sites.json', 'r') as file:\n",
    "    measurement_sites = pd.read_json(file)\n",
    "\n",
    "df_list = [{'station': key, 'altitude': value['altitude'], 'environment_type': value['environment_type']} for key, value in measurement_sites.items()]\n",
    "measurement_sites = pd.DataFrame(df_list)\n",
    "\n",
    "data = pd.merge(data, measurement_sites, on='station', how='left')\n",
    "\n",
    "# One-hot encode 'environment_type'\n",
    "encoded_environment = pd.get_dummies(data['environment_type'], prefix='env_type')\n",
    "data = pd.concat([data, encoded_environment], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>n100</th>\n",
       "      <th>aermr01</th>\n",
       "      <th>aermr02</th>\n",
       "      <th>aermr03</th>\n",
       "      <th>aermr04</th>\n",
       "      <th>...</th>\n",
       "      <th>rh</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>altitude</th>\n",
       "      <th>environment_type</th>\n",
       "      <th>env_type_coastal</th>\n",
       "      <th>env_type_remote</th>\n",
       "      <th>env_type_rural</th>\n",
       "      <th>env_type_rural_regional_background</th>\n",
       "      <th>env_type_urban</th>\n",
       "      <th>env_type_urban_background</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABZ-2012-01-26 18:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 18:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2994.733333</td>\n",
       "      <td>1.130925e-11</td>\n",
       "      <td>9.656489e-10</td>\n",
       "      <td>5.386068e-11</td>\n",
       "      <td>8.925737e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>85.351851</td>\n",
       "      <td>2.343428</td>\n",
       "      <td>545</td>\n",
       "      <td>urban_background</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABZ-2012-01-26 21:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 21:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2780.725000</td>\n",
       "      <td>1.221719e-11</td>\n",
       "      <td>1.043291e-09</td>\n",
       "      <td>4.078474e-11</td>\n",
       "      <td>1.820321e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>87.455067</td>\n",
       "      <td>2.290729</td>\n",
       "      <td>545</td>\n",
       "      <td>urban_background</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABZ-2012-01-27 00:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-27 00:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2098.000000</td>\n",
       "      <td>7.723116e-12</td>\n",
       "      <td>6.594735e-10</td>\n",
       "      <td>1.707053e-11</td>\n",
       "      <td>8.950445e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>90.734149</td>\n",
       "      <td>1.933842</td>\n",
       "      <td>545</td>\n",
       "      <td>urban_background</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABZ-2012-01-27 03:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-27 03:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>1796.350000</td>\n",
       "      <td>4.699148e-12</td>\n",
       "      <td>4.011062e-10</td>\n",
       "      <td>8.261608e-12</td>\n",
       "      <td>3.943629e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>90.393698</td>\n",
       "      <td>1.588926</td>\n",
       "      <td>545</td>\n",
       "      <td>urban_background</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABZ-2012-01-27 06:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-27 06:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>1997.300000</td>\n",
       "      <td>3.720708e-12</td>\n",
       "      <td>3.175671e-10</td>\n",
       "      <td>4.759155e-12</td>\n",
       "      <td>1.120592e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>90.239081</td>\n",
       "      <td>1.724053</td>\n",
       "      <td>545</td>\n",
       "      <td>urban_background</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id station                 date  latitude  longitude  \\\n",
       "0  ABZ-2012-01-26 18:00:00     ABZ  2012-01-26 18:00:00     50.57      12.99   \n",
       "1  ABZ-2012-01-26 21:00:00     ABZ  2012-01-26 21:00:00     50.57      12.99   \n",
       "2  ABZ-2012-01-27 00:00:00     ABZ  2012-01-27 00:00:00     50.57      12.99   \n",
       "3  ABZ-2012-01-27 03:00:00     ABZ  2012-01-27 03:00:00     50.57      12.99   \n",
       "4  ABZ-2012-01-27 06:00:00     ABZ  2012-01-27 06:00:00     50.57      12.99   \n",
       "\n",
       "          n100       aermr01       aermr02       aermr03       aermr04  ...  \\\n",
       "0  2994.733333  1.130925e-11  9.656489e-10  5.386068e-11  8.925737e-15  ...   \n",
       "1  2780.725000  1.221719e-11  1.043291e-09  4.078474e-11  1.820321e-15  ...   \n",
       "2  2098.000000  7.723116e-12  6.594735e-10  1.707053e-11  8.950445e-14  ...   \n",
       "3  1796.350000  4.699148e-12  4.011062e-10  8.261608e-12  3.943629e-13  ...   \n",
       "4  1997.300000  3.720708e-12  3.175671e-10  4.759155e-12  1.120592e-12  ...   \n",
       "\n",
       "          rh  wind_speed  altitude  environment_type  env_type_coastal  \\\n",
       "0  85.351851    2.343428       545  urban_background                 0   \n",
       "1  87.455067    2.290729       545  urban_background                 0   \n",
       "2  90.734149    1.933842       545  urban_background                 0   \n",
       "3  90.393698    1.588926       545  urban_background                 0   \n",
       "4  90.239081    1.724053       545  urban_background                 0   \n",
       "\n",
       "   env_type_remote  env_type_rural  env_type_rural_regional_background  \\\n",
       "0                0               0                                   0   \n",
       "1                0               0                                   0   \n",
       "2                0               0                                   0   \n",
       "3                0               0                                   0   \n",
       "4                0               0                                   0   \n",
       "\n",
       "   env_type_urban  env_type_urban_background  \n",
       "0               0                          1  \n",
       "1               0                          1  \n",
       "2               0                          1  \n",
       "3               0                          1  \n",
       "4               0                          1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/gap_filling_station_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
