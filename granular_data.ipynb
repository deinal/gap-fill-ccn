{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the measurement station codes (35 stations)\n",
    "# more detailed information on the stations can be found in metadata/measurement_sites_info.txt\n",
    "stations = ['ABZ', 'ALE', 'AMA', 'AMM', 'ASP', 'BEI', 'BOT', 'BSL', 'DEL', 'EGB',\n",
    "            'FKL', 'HAD', 'HEL', 'HPB', 'HRW', 'HYY', 'KCE', 'KPZ', 'MAR', 'MHD', \n",
    "            'MLP', 'MUK', 'NAN', 'NEU', 'POV', 'SAO', 'SCH', 'SGP', 'UAE', 'PRL',\n",
    "            'VAR', 'VHL', 'VIE', 'WAL', 'ZOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets(folder):\n",
    "    '''\n",
    "    Concatenates the individual datasets for all measurement stations in a specified folder located in \"data/\".\n",
    "    \n",
    "    Parameters:\n",
    "    folder (str): Name of folder located in the \"data/\" folder of the repository\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: data frame of the concatenated data sets in the folder\n",
    "    '''\n",
    "    \n",
    "    full_df = []\n",
    "\n",
    "    for s in stations:\n",
    "        df = pd.read_csv('data/'+folder+'/'+s+'.csv')\n",
    "        df['station'] = s\n",
    "        full_df.append(df)\n",
    "\n",
    "    full_df = pd.concat(full_df)\n",
    "    full_df = full_df.reset_index(drop=True)\n",
    "    full_df['id'] = [full_df.station[i] + '-' + str(full_df.date[i]) for i in range(full_df.shape[0])]\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the aerosol mixing ratio data and saving it as a separate csv file\n",
    "# a full description of all variable names can be found in metadata/variable_names.txt\n",
    "aerosols_df = combine_datasets('aerosols')\n",
    "aerosols_df = aerosols_df[['id', 'date', 'station', 'latitude', 'longitude', 'aermr01', 'aermr02', \n",
    "                           'aermr03', 'aermr04', 'aermr05', 'aermr06', 'aermr07', \n",
    "                           'aermr08', 'aermr09', 'aermr10', 'aermr11']]\n",
    "aerosols_df.to_csv('data/aerosols_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the atmospheric data, calculating the relative humidity, and saving it as a separate csv file\n",
    "atmospheric_df = combine_datasets('atmospheric')\n",
    "atmospheric_df = atmospheric_df[['id', 'd2m', 't2m']]\n",
    "td = atmospheric_df.d2m - 273.15\n",
    "t = atmospheric_df.t2m - 273.15\n",
    "atmospheric_df['rh'] = 100*(np.exp((17.625*td) / (243.04+td)) / np.exp((17.625*t) / (243.04+t)))\n",
    "atmospheric_df.to_csv('data/atmospheric_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the boundary layer height data and saving it as a separate csv file\n",
    "boundary_layer_height_df = combine_datasets('boundary_layer_height')\n",
    "boundary_layer_height_df = boundary_layer_height_df[['id', 'blh']]\n",
    "boundary_layer_height_df.to_csv('data/boundary_layer_height_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the gas data and saving it as a separate csv file\n",
    "gases_df = combine_datasets('gases')\n",
    "gases_df = gases_df[['id', 'co', 'c5h8', 'no2', 'no', 'so2']]\n",
    "gases_df.to_csv('data/gases_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the slow access data and saving it as a separate csv file\n",
    "slow_access_df = combine_datasets('slow_access')\n",
    "slow_access_df = slow_access_df[['id', 'nh3', 'crwc', 'c10h16']]\n",
    "slow_access_df.to_csv('data/slow_access_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the wind data, calculating the wind speed, and saving it as a separate csv file\n",
    "wind_df = combine_datasets('wind')\n",
    "wind_df['wind_speed'] = np.sqrt(wind_df.u**2 + wind_df.v**2)\n",
    "wind_df = wind_df[['id', 'wind_speed']]\n",
    "wind_df.to_csv('data/wind.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>aermr01</th>\n",
       "      <th>aermr02</th>\n",
       "      <th>aermr03</th>\n",
       "      <th>aermr04</th>\n",
       "      <th>aermr05</th>\n",
       "      <th>aermr06</th>\n",
       "      <th>...</th>\n",
       "      <th>nh3</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>d2m</th>\n",
       "      <th>t2m</th>\n",
       "      <th>crwc</th>\n",
       "      <th>blh</th>\n",
       "      <th>rh</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>9.728344e-12</td>\n",
       "      <td>8.303498e-10</td>\n",
       "      <td>1.977892e-10</td>\n",
       "      <td>4.955472e-13</td>\n",
       "      <td>8.809125e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.947672e-10</td>\n",
       "      <td>3.451908e-10</td>\n",
       "      <td>1.688608e-08</td>\n",
       "      <td>4.579990e-09</td>\n",
       "      <td>274.34976</td>\n",
       "      <td>274.74243</td>\n",
       "      <td>6.662354e-07</td>\n",
       "      <td>226.21110</td>\n",
       "      <td>97.224089</td>\n",
       "      <td>2.388552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-01 03:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>1.149119e-11</td>\n",
       "      <td>9.807117e-10</td>\n",
       "      <td>3.608436e-10</td>\n",
       "      <td>8.954750e-13</td>\n",
       "      <td>1.505326e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.704389e-10</td>\n",
       "      <td>5.595195e-10</td>\n",
       "      <td>1.851567e-08</td>\n",
       "      <td>3.697133e-09</td>\n",
       "      <td>275.56702</td>\n",
       "      <td>275.84317</td>\n",
       "      <td>1.356097e-06</td>\n",
       "      <td>227.60513</td>\n",
       "      <td>98.057947</td>\n",
       "      <td>2.525840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-01 06:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>1.498656e-11</td>\n",
       "      <td>1.278999e-09</td>\n",
       "      <td>5.850223e-10</td>\n",
       "      <td>1.004596e-12</td>\n",
       "      <td>1.536192e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.911320e-10</td>\n",
       "      <td>7.258628e-10</td>\n",
       "      <td>1.803737e-08</td>\n",
       "      <td>1.453171e-09</td>\n",
       "      <td>276.51514</td>\n",
       "      <td>276.86853</td>\n",
       "      <td>3.219190e-06</td>\n",
       "      <td>296.77762</td>\n",
       "      <td>97.541081</td>\n",
       "      <td>2.777447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-01 09:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>1.326326e-11</td>\n",
       "      <td>1.131177e-09</td>\n",
       "      <td>6.964777e-10</td>\n",
       "      <td>6.364222e-13</td>\n",
       "      <td>8.816045e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.703658e-10</td>\n",
       "      <td>1.102613e-09</td>\n",
       "      <td>1.353255e-08</td>\n",
       "      <td>1.221443e-09</td>\n",
       "      <td>277.77420</td>\n",
       "      <td>278.42493</td>\n",
       "      <td>1.323438e-07</td>\n",
       "      <td>641.16990</td>\n",
       "      <td>95.568645</td>\n",
       "      <td>3.490278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-01 12:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>7.933063e-12</td>\n",
       "      <td>6.726889e-10</td>\n",
       "      <td>3.573501e-10</td>\n",
       "      <td>2.600534e-13</td>\n",
       "      <td>4.015943e-13</td>\n",
       "      <td>2.105410e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122887e-10</td>\n",
       "      <td>7.667192e-10</td>\n",
       "      <td>8.655749e-09</td>\n",
       "      <td>1.667808e-09</td>\n",
       "      <td>279.82742</td>\n",
       "      <td>280.83896</td>\n",
       "      <td>3.709535e-07</td>\n",
       "      <td>586.82715</td>\n",
       "      <td>93.313550</td>\n",
       "      <td>3.836724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  station                date  latitude  longitude       aermr01  \\\n",
       "0     ABZ 2012-01-01 00:00:00     50.57      12.99  9.728344e-12   \n",
       "1     ABZ 2012-01-01 03:00:00     50.57      12.99  1.149119e-11   \n",
       "2     ABZ 2012-01-01 06:00:00     50.57      12.99  1.498656e-11   \n",
       "3     ABZ 2012-01-01 09:00:00     50.57      12.99  1.326326e-11   \n",
       "4     ABZ 2012-01-01 12:00:00     50.57      12.99  7.933063e-12   \n",
       "\n",
       "        aermr02       aermr03       aermr04       aermr05       aermr06  ...  \\\n",
       "0  8.303498e-10  1.977892e-10  4.955472e-13  8.809125e-13  0.000000e+00  ...   \n",
       "1  9.807117e-10  3.608436e-10  8.954750e-13  1.505326e-12  0.000000e+00  ...   \n",
       "2  1.278999e-09  5.850223e-10  1.004596e-12  1.536192e-12  0.000000e+00  ...   \n",
       "3  1.131177e-09  6.964777e-10  6.364222e-13  8.816045e-13  0.000000e+00  ...   \n",
       "4  6.726889e-10  3.573501e-10  2.600534e-13  4.015943e-13  2.105410e-13  ...   \n",
       "\n",
       "            nh3            no           no2           so2        d2m  \\\n",
       "0  4.947672e-10  3.451908e-10  1.688608e-08  4.579990e-09  274.34976   \n",
       "1  4.704389e-10  5.595195e-10  1.851567e-08  3.697133e-09  275.56702   \n",
       "2  3.911320e-10  7.258628e-10  1.803737e-08  1.453171e-09  276.51514   \n",
       "3  3.703658e-10  1.102613e-09  1.353255e-08  1.221443e-09  277.77420   \n",
       "4  6.122887e-10  7.667192e-10  8.655749e-09  1.667808e-09  279.82742   \n",
       "\n",
       "         t2m          crwc        blh         rh  wind_speed  \n",
       "0  274.74243  6.662354e-07  226.21110  97.224089    2.388552  \n",
       "1  275.84317  1.356097e-06  227.60513  98.057947    2.525840  \n",
       "2  276.86853  3.219190e-06  296.77762  97.541081    2.777447  \n",
       "3  278.42493  1.323438e-07  641.16990  95.568645    3.490278  \n",
       "4  280.83896  3.709535e-07  586.82715  93.313550    3.836724  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining all the data sets into one dataframe\n",
    "data = aerosols_df.merge(atmospheric_df, on='id')\n",
    "data = data.merge(boundary_layer_height_df, on='id')\n",
    "data = data.merge(gases_df, on='id')\n",
    "data = data.merge(slow_access_df, on='id')\n",
    "data = data.merge(wind_df, on='id')\n",
    "\n",
    "# reordering the columns\n",
    "data = data[['station', 'date', 'latitude', 'longitude', \n",
    "             'aermr01', 'aermr02', 'aermr03', 'aermr04', 'aermr05', 'aermr06', 'aermr07', \n",
    "             'aermr08', 'aermr09', 'aermr10', 'aermr11', 'co', 'c5h8', 'c10h16', 'nh3', \n",
    "             'no', 'no2', 'so2', 'd2m', 't2m', 'crwc', 'blh', 'rh', 'wind_speed']]\n",
    "\n",
    "# saving the full dataset\n",
    "data.date = pd.to_datetime(data.date)\n",
    "data.dropna(inplace=True)\n",
    "data.to_csv('data/covariates.csv', index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the n100 data and saving it as a separate csv file\n",
    "n100_df = []\n",
    "for s in stations:\n",
    "    df = pd.read_table(f'data/N100_proxy/{s}_N100.dat', sep='\\s+', \n",
    "                       names=['year', 'month', 'day', 'hour', 'minute', 'n100'])\n",
    "    \n",
    "    # AMA and UAE are in UTC, so the times of the measurements need to be adjusted to local time\n",
    "    if (s == 'AMA'):\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.date -= timedelta(hours=4)     \n",
    "    elif (s == 'UAE'):\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.date += timedelta(hours=4)\n",
    "        \n",
    "    # the year for FKL is multiplied by 2 due to some bug, so needs to be corrected\n",
    "    elif (s == 'FKL'):\n",
    "        df.year /= 2\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])  \n",
    "    # removing outliers for VHL\n",
    "    elif (s == 'VHL'):\n",
    "        for i, row in df.iterrows():\n",
    "            if row.n100 > 10000:\n",
    "                df.drop(index=i, inplace=True)\n",
    "    else:\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        \n",
    "    df.drop(columns=['year', 'month', 'day', 'hour', 'minute'], inplace=True)\n",
    "    \n",
    "    df['station'] = s\n",
    "    n100_df.append(df)\n",
    "\n",
    "n100_df = pd.concat(n100_df)\n",
    "n100_df = n100_df.reset_index(drop=True)\n",
    "n100_df = n100_df.drop_duplicates()\n",
    "n100_df.loc[n100_df['n100'] <= 0, 'n100'] = np.nan\n",
    "# n100_df['id'] = [n100_df.station[i] + '-' + str(n100_df.date[i]) for i in range(n100_df.shape[0])]\n",
    "n100_df = n100_df[['station', 'date', 'n100']]\n",
    "n100_df.to_csv('data/n100_granular_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n100_df = pd.read_csv('data/n100_granular_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>n100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 17:30:00</td>\n",
       "      <td>2967.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 18:29:00</td>\n",
       "      <td>2756.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 19:30:00</td>\n",
       "      <td>3260.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 20:30:00</td>\n",
       "      <td>3013.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 21:29:00</td>\n",
       "      <td>2525.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station                 date    n100\n",
       "0     ABZ  2012-01-26 17:30:00  2967.4\n",
       "1     ABZ  2012-01-26 18:29:00  2756.7\n",
       "2     ABZ  2012-01-26 19:30:00  3260.1\n",
       "3     ABZ  2012-01-26 20:30:00  3013.8\n",
       "4     ABZ  2012-01-26 21:29:00  2525.4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n100_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_with_time_limit(df, column, time_limit):\n",
    "    jd_max_gap_fill = time_limit / (60*24)\n",
    "    \n",
    "    # calculate the value gap\n",
    "    df['ffill'] = df[column].ffill()\n",
    "    df['value_gap'] = df[column].bfill() - df[column].ffill()\n",
    "\n",
    "    # get the Julian date for the entry\n",
    "    df['jd'] = df.index.to_julian_date()\n",
    "\n",
    "    # calculate the time gap\n",
    "    df['jd_nan'] = np.where(~df[column].isna(), df['jd'], np.nan)\n",
    "    df['jd_gap'] = df['jd_nan'].bfill() - df['jd_nan'].ffill()\n",
    "    \n",
    "    # time-wise, calculate how far into the value gap we are\n",
    "    df['jd_start'] = df['jd_nan'].ffill() \n",
    "    df['jd_prp'] = np.where(df['jd_gap'] != 0, (df['jd'] - df['jd_start']) / df['jd_gap'], 0)\n",
    "    \n",
    "    # calculate time-interpolated values\n",
    "    filled_value = np.where(df['jd_gap'] <= jd_max_gap_fill, df['ffill'] + df['value_gap'] * df['jd_prp'], np.nan) \n",
    "\n",
    "    return filled_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABZ mode diff: 59 min \t gaps: 14154 -> 14154\n",
      "ALE mode diff: 14 min \t gaps: 12085 -> 11909\n",
      "AMA mode diff: 5 min \t gaps: 109386 -> 109217\n",
      "AMM mode diff: 5 min \t gaps: 7399 -> 7306\n",
      "ASP mode diff: 59 min \t gaps: 33341 -> 33341\n",
      "BEI mode diff: 8 min \t gaps: 33828 -> 33671\n",
      "BOT mode diff: 9 min \t gaps: 23551 -> 23197\n",
      "BSL mode diff: 60 min \t gaps: 8017 -> 8017\n",
      "DEL mode diff: 60 min \t gaps: 5133 -> 5133\n",
      "EGB mode diff: 15 min \t gaps: 4308 -> 4153\n",
      "FKL mode diff: 5 min \t gaps: 31054 -> 30944\n",
      "HAD mode diff: 5 min \t gaps: 85126 -> 84848\n",
      "HEL mode diff: 10 min \t gaps: 19966 -> 18036\n",
      "HPB mode diff: 60 min \t gaps: 9902 -> 9902\n",
      "HRW mode diff: 60 min \t gaps: 3503 -> 3503\n",
      "HYY mode diff: 10 min \t gaps: 17663 -> 13160\n",
      "KCE mode diff: 60 min \t gaps: 8430 -> 8430\n",
      "KPZ mode diff: 9 min \t gaps: 167412 -> 167191\n",
      "MAR mode diff: 9 min \t gaps: 27342 -> 27144\n",
      "MHD mode diff: 59 min \t gaps: 8536 -> 8536\n",
      "MLP mode diff: 60 min \t gaps: 12405 -> 12405\n",
      "MUK mode diff: 60 min \t gaps: 11068 -> 11068\n",
      "NAN mode diff: 9 min \t gaps: 20458 -> 20081\n",
      "NEU mode diff: 60 min \t gaps: 6189 -> 6189\n",
      "POV mode diff: 180 min \t gaps: 5978 -> 5978\n",
      "SAO mode diff: 14 min \t gaps: 8202 -> 8165\n",
      "SCH mode diff: 60 min \t gaps: 21381 -> 21381\n",
      "SGP mode diff: 44 min \t gaps: 11286 -> 11286\n",
      "UAE mode diff: 6 min \t gaps: 37141 -> 37064\n",
      "PRL mode diff: 60 min \t gaps: 31060 -> 31060\n",
      "VAR mode diff: 10 min \t gaps: 58822 -> 32326\n",
      "VHL mode diff: 11 min \t gaps: 9108 -> 8810\n",
      "VIE mode diff: 60 min \t gaps: 4041 -> 4041\n",
      "WAL mode diff: 61 min \t gaps: 2459 -> 2459\n",
      "ZOT mode diff: 60 min \t gaps: 6016 -> 6016\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for station in stations:\n",
    "    df_station = n100_df[n100_df['station'] == station].copy()\n",
    "\n",
    "    # convert date column to datetime and set as index\n",
    "    df_station['date'] = pd.to_datetime(df_station['date'])\n",
    "    df_station.set_index('date', inplace=True)\n",
    "    \n",
    "    # remove duplicate measurements\n",
    "    df_station = df_station[~df_station.index.duplicated()]\n",
    "    \n",
    "    # compute the difference between consecutive rows\n",
    "    differences = df_station['n100'].diff()\n",
    "    # filter out rows where the difference is zero\n",
    "    df_station = df_station[differences != 0]\n",
    "\n",
    "    # calculate time diffs between rows in minutes\n",
    "    time_diffs = df_station.index.to_series().diff().dt.total_seconds().div(60).dropna()\n",
    "    # compute the mode\n",
    "    mode_diff = time_diffs.mode()[0] # mode() returns a Series, get the first value\n",
    "    # create a new dataframe by resampling the original\n",
    "    df_resampled = df_station.resample(f'{int(mode_diff)}T').asfreq()\n",
    "    # merge the original dataframe with the resampled one\n",
    "    df_station = pd.concat([df_station, df_resampled]).sort_index()\n",
    "    \n",
    "    # reset index\n",
    "    df_station.reset_index(inplace=True)\n",
    "    df_station.rename(columns={'index': 'date'}, inplace=True)\n",
    "    # drop duplicate rows\n",
    "    df_station.drop_duplicates(inplace=True)\n",
    "    # set index back to date\n",
    "    df_station.set_index('date', inplace=True)\n",
    "\n",
    "    # calculate the time difference to the previous row in minutes\n",
    "    time_diff_prev_row = df_station.index.to_series().diff().dt.total_seconds().div(60).abs()\n",
    "    # calculate the time difference to the next row in minutes\n",
    "    time_diff_next_row = df_station.index.to_series().diff(-1).dt.total_seconds().div(60).abs()\n",
    "    # create a mask where 'n100' is NaN and the difference between current row and previous/next row is less than mode_diff - 1\n",
    "    mask = (df_station['n100'].isna()) & ((time_diff_prev_row < mode_diff - 1) | (time_diff_next_row < mode_diff - 1))\n",
    "    # drop these rows\n",
    "    df_station = df_station.loc[~mask]\n",
    "    \n",
    "    # set station again\n",
    "    df_station['station'] = station\n",
    "    \n",
    "    # drop leading NaNs\n",
    "    df_station = df_station.loc[pd.notna(df_station['n100']).idxmax():]\n",
    "    # drop trailing NaNs\n",
    "    df_station = df_station.loc[:df_station['n100'].notna()[::-1].idxmax()]\n",
    "    \n",
    "    # interpolate sequences 1 hour or shorter\n",
    "    nans_before = df_station.n100.isna().sum()\n",
    "    df_station['n100_filled'] = interpolate_with_time_limit(df_station.copy(), column='n100', time_limit=60)\n",
    "    df_station['interpolated'] = (df_station['n100'] != df_station['n100_filled']) & ~(df_station['n100'].isna() & df_station['n100_filled'].isna())\n",
    "    df_station['n100'] = df_station['n100_filled']\n",
    "    df_station.drop(columns=['n100_filled'], inplace=True)\n",
    "    nans_after = df_station.n100.isna().sum()\n",
    "    \n",
    "    # append processed dataframe to the list\n",
    "    dfs.append(df_station)\n",
    "    \n",
    "    print(f'{station} mode diff: {int(mode_diff)} min \\t gaps: {nans_before} -> {nans_after}')\n",
    "\n",
    "# concatenate all dataframes\n",
    "df_final = pd.concat(dfs)\n",
    "\n",
    "df_final.to_csv('data/n100_final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>n100</th>\n",
       "      <th>interpolated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-26 17:30:00</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2967.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-26 18:29:00</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2756.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-26 19:30:00</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>3260.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-26 20:30:00</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>3013.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-26 21:29:00</th>\n",
       "      <td>ABZ</td>\n",
       "      <td>2525.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    station    n100  interpolated\n",
       "date                                             \n",
       "2012-01-26 17:30:00     ABZ  2967.4         False\n",
       "2012-01-26 18:29:00     ABZ  2756.7         False\n",
       "2012-01-26 19:30:00     ABZ  3260.1         False\n",
       "2012-01-26 20:30:00     ABZ  3013.8         False\n",
       "2012-01-26 21:29:00     ABZ  2525.4         False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.read_csv('data/n100_final_data.csv')\n",
    "df_final['date'] = pd.to_datetime(df_final['date'])\n",
    "df_final.set_index('date', inplace=True)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated 35629 / 5087274\n"
     ]
    }
   ],
   "source": [
    "print(f'Interpolated {df_final.interpolated.sum()} / {df_final.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station: ABZ\n",
      "Number of NaNs: 14154\n",
      "Number of gaps: 497\n",
      "Min: 1 Max: 4614\n",
      "Mean: 28.48 Std: 249.76\n",
      "-----------------------------\n",
      "Station: ALE\n",
      "Number of NaNs: 11909\n",
      "Number of gaps: 553\n",
      "Min: 2 Max: 1371\n",
      "Mean: 21.54 Std: 67.72\n",
      "-----------------------------\n",
      "Station: AMA\n",
      "Number of NaNs: 109217\n",
      "Number of gaps: 122\n",
      "Min: 10 Max: 31074\n",
      "Mean: 895.22 Std: 3585.44\n",
      "-----------------------------\n",
      "Station: AMM\n",
      "Number of NaNs: 7306\n",
      "Number of gaps: 27\n",
      "Min: 11 Max: 2701\n",
      "Mean: 270.59 Std: 576.26\n",
      "-----------------------------\n",
      "Station: ASP\n",
      "Number of NaNs: 33341\n",
      "Number of gaps: 55\n",
      "Min: 1 Max: 29678\n",
      "Mean: 606.2 Std: 3997.01\n",
      "-----------------------------\n",
      "Station: BEI\n",
      "Number of NaNs: 33671\n",
      "Number of gaps: 100\n",
      "Min: 3 Max: 4866\n",
      "Mean: 336.71 Std: 647.89\n",
      "-----------------------------\n",
      "Station: BOT\n",
      "Number of NaNs: 23197\n",
      "Number of gaps: 124\n",
      "Min: 5 Max: 2718\n",
      "Mean: 187.07 Std: 506.68\n",
      "-----------------------------\n",
      "Station: BSL\n",
      "Number of NaNs: 8017\n",
      "Number of gaps: 24\n",
      "Min: 1 Max: 4416\n",
      "Mean: 334.04 Std: 970.63\n",
      "-----------------------------\n",
      "Station: DEL\n",
      "Number of NaNs: 5133\n",
      "Number of gaps: 98\n",
      "Min: 1 Max: 808\n",
      "Mean: 52.38 Std: 122.48\n",
      "-----------------------------\n",
      "Station: EGB\n",
      "Number of NaNs: 4153\n",
      "Number of gaps: 31\n",
      "Min: 3 Max: 724\n",
      "Mean: 133.97 Std: 184.43\n",
      "-----------------------------\n",
      "Station: FKL\n",
      "Number of NaNs: 30944\n",
      "Number of gaps: 26\n",
      "Min: 11 Max: 8738\n",
      "Mean: 1190.15 Std: 2304.54\n",
      "-----------------------------\n",
      "Station: HAD\n",
      "Number of NaNs: 84848\n",
      "Number of gaps: 101\n",
      "Min: 12 Max: 22950\n",
      "Mean: 840.08 Std: 3447.91\n",
      "-----------------------------\n",
      "Station: HEL\n",
      "Number of NaNs: 18036\n",
      "Number of gaps: 175\n",
      "Min: 4 Max: 1750\n",
      "Mean: 103.06 Std: 181.42\n",
      "-----------------------------\n",
      "Station: HPB\n",
      "Number of NaNs: 9902\n",
      "Number of gaps: 62\n",
      "Min: 1 Max: 4343\n",
      "Mean: 159.71 Std: 643.87\n",
      "-----------------------------\n",
      "Station: HRW\n",
      "Number of NaNs: 3503\n",
      "Number of gaps: 71\n",
      "Min: 9 Max: 717\n",
      "Mean: 49.34 Std: 91.95\n",
      "-----------------------------\n",
      "Station: HYY\n",
      "Number of NaNs: 13160\n",
      "Number of gaps: 308\n",
      "Min: 4 Max: 584\n",
      "Mean: 42.73 Std: 76.23\n",
      "-----------------------------\n",
      "Station: KCE\n",
      "Number of NaNs: 8430\n",
      "Number of gaps: 268\n",
      "Min: 1 Max: 1008\n",
      "Mean: 31.46 Std: 117.32\n",
      "-----------------------------\n",
      "Station: KPZ\n",
      "Number of NaNs: 167191\n",
      "Number of gaps: 195\n",
      "Min: 6 Max: 52638\n",
      "Mean: 857.39 Std: 5200.26\n",
      "-----------------------------\n",
      "Station: MAR\n",
      "Number of NaNs: 27144\n",
      "Number of gaps: 115\n",
      "Min: 5 Max: 8602\n",
      "Mean: 236.03 Std: 875.28\n",
      "-----------------------------\n",
      "Station: MHD\n",
      "Number of NaNs: 8536\n",
      "Number of gaps: 39\n",
      "Min: 1 Max: 5222\n",
      "Mean: 218.87 Std: 854.41\n",
      "-----------------------------\n",
      "Station: MLP\n",
      "Number of NaNs: 12405\n",
      "Number of gaps: 170\n",
      "Min: 1 Max: 4346\n",
      "Mean: 72.97 Std: 399.26\n",
      "-----------------------------\n",
      "Station: MUK\n",
      "Number of NaNs: 11068\n",
      "Number of gaps: 870\n",
      "Min: 1 Max: 1989\n",
      "Mean: 12.72 Std: 73.16\n",
      "-----------------------------\n",
      "Station: NAN\n",
      "Number of NaNs: 20081\n",
      "Number of gaps: 98\n",
      "Min: 5 Max: 1769\n",
      "Mean: 204.91 Std: 310.91\n",
      "-----------------------------\n",
      "Station: NEU\n",
      "Number of NaNs: 6189\n",
      "Number of gaps: 39\n",
      "Min: 1 Max: 4226\n",
      "Mean: 158.69 Std: 686.24\n",
      "-----------------------------\n",
      "Station: POV\n",
      "Number of NaNs: 5978\n",
      "Number of gaps: 310\n",
      "Min: 1 Max: 1593\n",
      "Mean: 19.28 Std: 125.71\n",
      "-----------------------------\n",
      "Station: SAO\n",
      "Number of NaNs: 8165\n",
      "Number of gaps: 51\n",
      "Min: 3 Max: 1750\n",
      "Mean: 160.1 Std: 318.4\n",
      "-----------------------------\n",
      "Station: SCH\n",
      "Number of NaNs: 21381\n",
      "Number of gaps: 131\n",
      "Min: 1 Max: 12055\n",
      "Mean: 163.21 Std: 1071.59\n",
      "-----------------------------\n",
      "Station: SGP\n",
      "Number of NaNs: 11286\n",
      "Number of gaps: 1572\n",
      "Min: 1 Max: 1030\n",
      "Mean: 7.18 Std: 48.52\n",
      "-----------------------------\n",
      "Station: UAE\n",
      "Number of NaNs: 37064\n",
      "Number of gaps: 36\n",
      "Min: 9 Max: 13213\n",
      "Mean: 1029.56 Std: 2369.69\n",
      "-----------------------------\n",
      "Station: PRL\n",
      "Number of NaNs: 31060\n",
      "Number of gaps: 56\n",
      "Min: 1 Max: 20696\n",
      "Mean: 554.64 Std: 2818.3\n",
      "-----------------------------\n",
      "Station: VAR\n",
      "Number of NaNs: 32326\n",
      "Number of gaps: 389\n",
      "Min: 5 Max: 1927\n",
      "Mean: 83.1 Std: 199.71\n",
      "-----------------------------\n",
      "Station: VHL\n",
      "Number of NaNs: 8810\n",
      "Number of gaps: 34\n",
      "Min: 4 Max: 2864\n",
      "Mean: 259.12 Std: 561.16\n",
      "-----------------------------\n",
      "Station: VIE\n",
      "Number of NaNs: 4041\n",
      "Number of gaps: 38\n",
      "Min: 1 Max: 897\n",
      "Mean: 106.34 Std: 226.41\n",
      "-----------------------------\n",
      "Station: WAL\n",
      "Number of NaNs: 2459\n",
      "Number of gaps: 81\n",
      "Min: 1 Max: 662\n",
      "Mean: 30.36 Std: 95.3\n",
      "-----------------------------\n",
      "Station: ZOT\n",
      "Number of NaNs: 6016\n",
      "Number of gaps: 69\n",
      "Min: 1 Max: 1710\n",
      "Mean: 87.19 Std: 324.28\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_gaps(df):\n",
    "    stations = df['station'].unique()\n",
    "    for station in stations:\n",
    "        df_station = df[df['station'] == station]\n",
    "        gaps = df_station['n100'].isna()\n",
    "        print(f'Station: {station}')\n",
    "        print(f'Number of NaNs: {gaps.sum()}')\n",
    "        gap_lengths = gaps.diff().ne(0).cumsum()[gaps].value_counts().sort_index()\n",
    "        print('Number of gaps:', len(gap_lengths))\n",
    "        print('Min:', gap_lengths.min(), 'Max:', gap_lengths.max())\n",
    "        print('Mean:', round(gap_lengths.mean(), 2), 'Std:', round(gap_lengths.std(), 2))\n",
    "        print(\"-----------------------------\")\n",
    "\n",
    "print_gaps(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
